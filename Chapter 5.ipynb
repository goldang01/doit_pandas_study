{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunset-project",
   "metadata": {},
   "source": [
    "# 5 데이터 연결하기\n",
    "\n",
    "이 장에서는 '분석하기 좋은 데이터 집합'을 만들기 위해 여러 개의 데이터 집합을 연결하거나 추출하여 데이터를 정리하는 방법에 대해 알아보겠습니다.\n",
    "\n",
    "#### 이 장을 보기 전에 알아두면 좋은 개념\n",
    "\n",
    "- 데이터 추출\n",
    "\n",
    "## 5-1 분석하기 좋은 데이터\n",
    "\n",
    "## 5-2 데이터 연결 기초\n",
    "\n",
    "## 5-3 데이터 연결 마무리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-surname",
   "metadata": {},
   "source": [
    "## 5-1 분석하기 좋은 데이터\n",
    "\n",
    "#### 분석하기 좋은 데이터란?\n",
    "\n",
    "분석하기 좋은 데이터란 데이터 집합을 분석하기 좋은 상태로 만들어 놓은 것을 말합니다.데이터 분석 단계에서 데이터 정리는 아주 중요합니다. 실제로 데이터 분석 작업의 70% 이상을 차지하고 있는 작업이 데이터 정리 작업이죠. 분석하기 좋은 데이터는 다음 조건을 만족해야 하며 이 조건을 만족하는 데이터를 특별히 깔끔한 데이터(Tidy Data)라고 부릅니다.\n",
    "\n",
    "#### 깔끔한 데이터의 조건\n",
    "\n",
    "- 데이터 분석 목적에 맞는 데이터를 모아 새로운 표(Table)를 만들어야 합니다.\n",
    "- 측정한 값은 행(row)을 구성해야 합니다.\n",
    "- 변수는 열(column)로 구성해야 합니다.\n",
    "\n",
    "아직은 깔끔한 데이터가 왜 중요한지 알 수 없겠지만 실습을 하나씩 진행하다 보면 깔끔한 데이터의 중요성에 대해 자연스럽게 이해할 수 있을 것입니다.\n",
    "\n",
    "#### 깔끔한 데이터는 데이터 연결부터\n",
    "\n",
    "예를 들어 주식 데이터를 분석하는 과정에서 '기업 정보'가 있는 데이터 집합과 '주식 가격'이 있는 데이터 집합이 있을 때 '*첨단 산업 기업의 주식 가격에 대한 데이터*'를 보려면 어떻게 해야 할까요? 일단 '기업 정보'에서 첨단 기술을 가진 기업을 찾아야 합니다. 그리고 이 기업들의 '주식 가격'을 찾아야겠죠. 그런 다음 찾아낸 2개의 데이터를 연결하면 됩니다. 이렇게 데이터 집합은 연관성이 깊은 값끼리 모여 있기 때문에 데이터 연결을 통해 필요한 데이터를 만드는 과정이 반드시 필요합니다. 그러면 다음 실습을 통해 데이터 연결을 어떻게 하는지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-crown",
   "metadata": {},
   "source": [
    "# 5-2 데이터 연결 기초\n",
    "\n",
    "### 데이터 연결하기\n",
    "\n",
    "#### 1. concat 메서드로 데이터 연결하기\n",
    "데이터를 연결하려면 concat 메서드를 사용하면 됩니다. 다음 예제를 통해 concat 메서드의 사용법을 익혀보겠습니다. 준비된 CSV 파일을 읽어 들여 변수 df1,2,3 에 저장합니다. concat은 연결(Concatenation)이라는 단어에서 따온 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unusual-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('./data/concat_1.csv')\n",
    "df2 = pd.read_csv('./data/concat_2.csv')\n",
    "df3 = pd.read_csv('./data/concat_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-theory",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "\n",
    "concat 메서드에 연결하려는 데이터프레임을 리스트에 담아 전달하면 연결한 데이터프레임을 반환합니다. concat 메서드는 데이터프레임을 연결할 때 위에서 아래 방향으로 연결합니다. 그리고 df1,2,3은 열의 이름이 모두 A,B,C,D로 같습니다. 그래서 데이터프레임을 연결한 다음에도 열이 그대로 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emotional-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-angle",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "연결한 데이터프레임에서 행 데이터를 추출해 볼까요? concat 메서드는 전달받은 리스트의 요소 순서대로 데이터를 연결합니다. 그래서 기존 데이터프레임에 있던 인덱스도 그대로 유지됩니다. 다음은 데이터프레임에서 네 번째 행을 추출한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generous-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(row_concat.iloc[3, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-imperial",
   "metadata": {},
   "source": [
    "#### 4. 데이터프레임에 시리즈 연결하기\n",
    "\n",
    "이번에는 데이터프레임에 시리즈를 추가해 보겠습니다. 먼저 리스트를 시리즈로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enabling-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-remains",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "\n",
    "concat 메서드로 데이터프레임과 시리즈를 연결해 볼까요? 시리즈가 새로운 행으로 추가될 것 같죠? 하지만 행이아니라 새로운 열로 추가됩니다. 그래서 NaN이라는 값도 많이 생겼습니다. 앞으로 NaN을 누락값이라고 부르겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "express-vacuum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_series]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-steel",
   "metadata": {},
   "source": [
    "### 행이 1개라도 반드시 데이터프레임에 담아 연결해야 합니다.\n",
    "\n",
    "시리즈를 데이터프레임의 새로운 행으로 연결하려고 하면 제대로 되지 않습니다. 왜 그럴까요? 시리즈에는 열 이름이 없기 때문입니다. 그래서 시리즈를 새로운 열로 간주하여 0이라는 이름의 열로 추가한 것이죠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-baptist",
   "metadata": {},
   "source": [
    "### 행 1개로 구성된 데이터프레임 생성하여 연결하기\n",
    "\n",
    "#### 1. \n",
    "\n",
    "시리즈는 행이 1개인 데이터프레임이라고 생각해도 됩니다. 다음은 1개의 행을 가지는 데이터프레임을 생성하여 df1에 연결한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "material-concrete",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "new_row_df = pd.DataFrame([['n1', 'n2', 'n3', 'n4']], columns=['A', 'B', 'C', 'D'])\n",
    "print(new_row_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "robust-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_df]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-lying",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "\n",
    "concat 메서드는 한 번에 2개 이상의 데이터프레임을 연결할 수 있는 메서드입니다. 만약 연결할 데이터프레임이 1개라면 append 메서드를 사용해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excessive-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(df1.append(new_row_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-sodium",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "\n",
    "append 메서드와 딕셔너리를 사용하면 더욱 간편하게 행을 연결할 수 있습니다. 이때 ignore_index를 True로 설정하면 데이터를 연결한 다음 데이터프레임의 인덱스를 0부터 다시 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indonesian-firewall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'A':'n1', 'B':'n2', 'C':'n3', 'D':'n4'}\n",
    "print(df1.append(data_dict, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-delhi",
   "metadata": {},
   "source": [
    "### 다양한 방법으로 데이터 연결하기\n",
    "\n",
    "판다스는 데이터를 연결하는 다양한 방법을 제공합니다. 다음 예제를 통해 데이터를 연결하는 다양한 방법에 대해 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-raise",
   "metadata": {},
   "source": [
    "#### 1. ignore_index 인자 사용하기\n",
    "\n",
    "바로 앞에서 실습했던 내용이죠? ignore_index를 True로 지정하면 데이터를 연결한 다음 데이터프레임의 인덱스를 0부터 다시 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "iraqi-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index = True)\n",
    "print(row_concat_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-committee",
   "metadata": {},
   "source": [
    "#### 2. 열 방향으로 데이터 연결하기\n",
    "\n",
    "만약 행 방향이 아니라 열 방향으로 데이터를 연결하려면 어떻게 해야 할까요? concat 메서드의 axis 인자를 1로 지정하면 됩니다. 다음은 df1, df2, df3을 열방향으로 연결한 것 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consistent-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-picking",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "\n",
    "만약 같은 열이름이 있는 데이터프레임에서 열 이름으로 데이터를 추출하면 해당 열 이름의 데이터를 모두 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "terminal-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n"
     ]
    }
   ],
   "source": [
    "print(col_concat['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-concentrate",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "\n",
    "다음과 같이 입력하면 간편하게 새로운 열을 추가할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alpine-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4\n"
     ]
    }
   ],
   "source": [
    "col_concat['new_col_list'] = ['n1','n2','n3','n4']\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-polls",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "\n",
    "과정 2에서는 데이터프레임의 열 이름을 유지한 채 연결했기 때문에 열 이름이 중복되었습니다. 다음은 ignore_index를 True로 지정하여 열 이름을 다시 지정한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prepared-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], axis = 1, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-google",
   "metadata": {},
   "source": [
    "#### 6. 공통  열과 공통 인덱스만 연결하기\n",
    "\n",
    "만약 열 이름의 일부가 서로 다른 데이터프레임을 연결하면 어떻게 될까요? 앞에서 사용한 df1, df2, df3의 열 이름을 다시 지정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "catholic-lithuania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df1.columns = ['A','B','C','D']\n",
    "df2.columns = ['E','F','G','H']\n",
    "df3.columns = ['A','C','F','H']\n",
    "print(df1)\n",
    "print(type(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "patient-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    E   F   G   H\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df2)\n",
    "print(type(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "composed-lithuania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df3)\n",
    "print(type(df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-south",
   "metadata": {},
   "source": [
    "#### 7.\n",
    "\n",
    "새롭게 열 이름을 부여한 데이터프레임 3개를 concat 메서드로 연결해 보겠습니다. 어떻게 되었나요? 열이름이 정렬되며 연결되었습니다. 그리고 데이터프레임에 없는 열 이름의 데이터는 누락값으로 처리되었습니다. 누락값 없이 데이터를 연결하는 방법은 없을까요?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lyric-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "0  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "1  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "2  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "3  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "1   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "2  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "3  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-category",
   "metadata": {},
   "source": [
    "#### 8. \n",
    "데이터프레임의 공통 열만 골라 연결하면 누락값이 생기지 않을 것입니다. 공통 열만 골라서 연결하려면 join 인자를 inner로 지정해야 합니다. 아쉽게도 df1,df2,df3은 공통 열이 없습니다. 따라서 세 데이터프레임의 공통 열을 연결한 결괏값으로 Empty DataFrame이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "buried-rings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], join = 'inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-mathematics",
   "metadata": {},
   "source": [
    "#### 9.\n",
    "\n",
    "df1, df3의 공통 열만 골라 연결해 볼까요? 그러면 공통 열인 A와 C만 연결됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wanted-deputy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df3], ignore_index=False, join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-right",
   "metadata": {},
   "source": [
    "#### 10.\n",
    "\n",
    "이번에는 데이터프레임을 행 방향으로 연결해 볼까요? df1, df2, df3의 인덱스를 다시 지정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collected-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n"
     ]
    }
   ],
   "source": [
    "df1.index = [0, 1, 2, 3]\n",
    "df2.index = [4, 5, 6, 7]\n",
    "df3.index = [0, 2, 5, 7]\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excess-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "average-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-insertion",
   "metadata": {},
   "source": [
    "#### 11.\n",
    "\n",
    "concat 메서드로 df1, df2, df3을 행 방향으로 연결하면 과정2와 비슷한 결과가 출력 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "toxic-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-distribution",
   "metadata": {},
   "source": [
    "#### 12.\n",
    "\n",
    "과정 9와 비슷한 방법으로 df1, df3의 공통 행만 골라 연결해 볼까요? 그러면 공통 행인 0과 2만 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "primary-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df3], axis=1, join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-collapse",
   "metadata": {},
   "source": [
    "# 5-3 데이터 연결 마무리\n",
    "\n",
    "판다스는 데이터 연결 전용 메서드인 merge를 제공합니다. merge 메서드의 사용방법을 실습하면서 데이터 연결을 마무리하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-alaska",
   "metadata": {},
   "source": [
    "### merge 메서드 사용하기\n",
    "\n",
    "#### 1. \n",
    "\n",
    "다음은 특정 위치의 날씨 정보에 필요핸 데이터 집합을 모두 불러온 것입니다. person은 관측한 사람의 이름, site는 관측 위치, visited는 관측날짜, survey는 날씨 정보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "collective-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.read_csv('./data/survey_person.csv')\n",
    "site = pd.read_csv('./data/survey_site.csv')\n",
    "survey = pd.read_csv('./data/survey_survey.csv')\n",
    "visited= pd.read_csv('./data/survey_visited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "celtic-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n"
     ]
    }
   ],
   "source": [
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "monetary-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n"
     ]
    }
   ],
   "source": [
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "grave-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "retained-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "print(survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-block",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "\n",
    "visited 데이터프레임의 일부 데이터만 떼어 실습에 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "alike-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_subset = visited.loc[[0,2,6], ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-antarctica",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "merge 메서드는 기본적으로 내부 조인을 실행하며 메서드를 사용한 데이터프레임(site)을 왼쪽으로 지정하고 첫 번째 인잣값으로 지정한 데이터프레임(visited_subset)을 오른쪽으로 지정합니다. left_on, right_on 인자는 값이 일치해야 할 왼쪽과 오른쪽 데이터프레임의 열을 지정합니다. 즉, 왼쪽 데이터프레임(site)의 열(name)과 오른쪽 데이터프레임(visited)의 열(site)의 값이 일치하면 왼쪽 데이터프레임을 기준으로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "organizational-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "o2o_merge = site.merge(visited_subset, left_on='name', right_on='site')\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-concert",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "\n",
    "다음은 site, visited 데이터프레임을 이용하여 데이터를 연결한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "colonial-couple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "m2o_merge = site.merge(visited, left_on='name', right_on='site')\n",
    "print(m2o_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-comedy",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "\n",
    "다른데이터프레임에도 연결해 볼까요? 다음은 person, survey 데이터프레임과 visited, survey 데이터프레임을 merge 메서드로 연결한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "killing-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   personal   family  taken person quant  reading\n",
      "0   dyer    William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer    William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer    William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer    William     Dyer    622   dyer   sal     0.09\n",
      "4     pb      Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb      Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb      Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb      Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb      Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake   Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake   Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake   Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake   Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake   Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake   Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake   Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentina  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentina  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentina  Roerich    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "ps = person.merge(survey, left_on='ident', right_on='person')\n",
    "vs = visited.merge(survey, left_on='ident', right_on='taken')\n",
    "\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "honest-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3         NaN    752   lake   rad     2.19\n",
      "14    752   DR-3         NaN    752   lake   sal     0.09\n",
      "15    752   DR-3         NaN    752   lake  temp   -16.00\n",
      "16    752   DR-3         NaN    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-inventory",
   "metadata": {},
   "source": [
    "#### 6. \n",
    "\n",
    "left_on, right_on 에 전달하는 값은 여러 개라도 상관이 없습니다. 다음과 같이 여러 개의 열 이름을 리스트에 담아 전달해도 됩니다. 다음은 ps데이터프레임의 ident, taken, quant, reading 열의 값과 vs 데이터프레임의 person,ident,quant,reading 열의 값을 이용하여 ps와 vs 데이터프레임을 서로 연결한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adaptive-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_vs = ps.merge(vs, left_on=['ident', 'taken', 'quant', 'reading'], right_on=['person', 'ident', 'quant', 'reading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-cruise",
   "metadata": {},
   "source": [
    "#### 7.\n",
    "\n",
    "과정 6에서 연결한 ps_vs 데이터프레임의 첫 번째 행을 살펴보면 양쪽 데이터프레임에 있덨던 중복된 열 이름(ident, taken, person)에 접미사 _x,_y가 추가되어 있는 것을 알 수 있습니다. _x는 왼쪽 데이터프레임의 열을 의미하고 _y는 오른쪽 데이터프레임의 열을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "spectacular-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident_x           dyer\n",
      "personal       William\n",
      "family            Dyer\n",
      "taken_x            619\n",
      "person_x          dyer\n",
      "quant              rad\n",
      "reading           9.82\n",
      "ident_y            619\n",
      "site              DR-1\n",
      "dated       1927-02-08\n",
      "taken_y            619\n",
      "person_y          dyer\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ps_vs.loc[0, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-index",
   "metadata": {},
   "source": [
    "#### 마무리하며\n",
    "\n",
    "이 장에서는 데이터를 연결하는 다향한 방법을 알아보았습니다. 특히 누락값과 중복값을 해결하기  위한 여러 가지 방법에 대해 알아보았습니다. 누락값과 중복값은 데이터 분석을 방해하는 요소가 될 수 있기 때문이죠. 5장을 시작하며 소개한 깔끔한 데이터의 조건 중 하나인'데이터 분석 목적에 맞는 데이터를 모아 새로운 표(table)를 만들어야 합니다'는 바로 누락값이나 중복값이 없는 상태로 데이터가 잘 연결되어 있어야 한다는 마입니다.\n",
    "\n",
    "출처: Doit 데이터 분석을 위한 판다스 입문"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
